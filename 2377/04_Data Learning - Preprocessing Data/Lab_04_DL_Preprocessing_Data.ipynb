{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ITAI 2377 Lab 04: Deep Learning Data Preprocessing\n",
        "\n",
        "**Instructor:** [Your Name]\n",
        "**Date:** [Date]\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome to Lab 04!  We'll explore the critical role of data preprocessing in deep learning. Even though models can extract features, preprocessing is essential for optimal performance. We'll cover various data types and apply preprocessing techniques. Resources in Google Colab are limited, so efficient coding is key!\n",
        "\n",
        "## Why Preprocess?\n",
        "\n",
        "Why preprocess when models extract features?\n",
        "\n",
        "*   **Standardization:** Models need consistent data formats and ranges.\n",
        "*   **Noise/Errors:** Raw data is messy. Preprocessing cleans it up.\n",
        "*   **Efficiency:** Cleaner data means faster training.\n",
        "*   **Results:** Good preprocessing helps models perform their best.\n",
        "\n",
        "Think of preprocessing as a personal trainer for your model.\n",
        "\n",
        "## Data Types and Preprocessing Techniques\n",
        "\n",
        "### 1. Image Data\n",
        "\n"
      ],
      "metadata": {
        "id": "nF2BwvLhgiLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import data, img_as_float\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a sample image (replace with your image path if you have one)\n",
        "image = data.camera()  # Or use: image = cv2.imread(\"path/to/your/image.jpg\")\n",
        "\n",
        "# Resizing (Student Code: Resize the image to (128, 128))\n",
        "# Hint: Use cv2.resize()\n",
        "# YOUR CODE HERE\n",
        "resized_image = cv2.resize(image, (128, 128))\n",
        "\n",
        "\n",
        "# Color space conversion (to grayscale)\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# Normalization (pixel values 0-1)\n",
        "normalized_image = img_as_float(image)\n",
        "\n",
        "# Display images\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 4, 1), plt.imshow(image), plt.title(\"Original\")\n",
        "plt.subplot(1, 4, 2), plt.imshow(resized_image), plt.title(\"Resized\")\n",
        "plt.subplot(1, 4, 3), plt.imshow(gray_image, cmap='gray'), plt.title(\"Grayscale\")\n",
        "plt.subplot(1, 4, 4), plt.imshow(normalized_image), plt.title(\"Normalized\")\n",
        "plt.show()\n",
        "\n",
        "# Data Augmentation (rotation - Student Code: Rotate by 30 degrees)\n",
        "# Hint: Use cv2.getRotationMatrix2D and cv2.warpAffine\n",
        "angle = 30 #YOUR CODE HERE\n",
        "rows, cols = image.shape[:2]\n",
        "M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "rotated_image = cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "plt.imshow(rotated_image), plt.title(\"Rotated\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "y1xo7aU3giLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Text Data\n",
        "\n"
      ],
      "metadata": {
        "id": "biPVje-6giLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "text = \"This is a fun example sentence with stop words and punctuation!\"\n",
        "\n",
        "# Tokenization (lowercase)\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Stop word removal (Student Code: Remove stop words and punctuation)\n",
        "# Hint: Use the 'stop_words' set and list comprehension\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# YOUR CODE HERE\n",
        "filtered_tokens = [w for w in tokens if not w in stop_words and w not in string.punctuation]\n",
        "\n",
        "\n",
        "# Lemmatization (Student Code: Lemmatize the filtered tokens)\n",
        "# Hint: Use WordNetLemmatizer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# YOUR CODE HERE\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(w) for w in filtered_tokens]\n",
        "\n",
        "\n",
        "print(\"Original:\", text)\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Filtered:\", filtered_tokens)\n",
        "print(\"Lemmatized:\", lemmatized_tokens)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "6HrW7Y0pgiLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Time Series Data\n",
        "\n"
      ],
      "metadata": {
        "id": "zJyKN_8AgiLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (with a missing value)\n",
        "data = {'Date': pd.to_datetime(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05']),\n",
        "        'Value': [10, 12, 15, np.nan, 18]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Missing value handling (Student Code: Use backward fill to fill missing values)\n",
        "# Hint: Use fillna() with method='bfill'\n",
        "# YOUR CODE HERE\n",
        "df['Value'].fillna(method='bfill', inplace=True)\n",
        "\n",
        "# Normalization (min-max scaling - Student Code: Normalize the 'Value' column)\n",
        "# YOUR CODE HERE\n",
        "min_val = df['Value'].min()\n",
        "max_val = df['Value'].max()\n",
        "df['Normalized'] = (df['Value'] - min_val) / (max_val - min_val)\n",
        "\n",
        "print(df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "qdvqJcaugiLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Optional: Video Data (Simplified)\n",
        "\n"
      ],
      "metadata": {
        "id": "L7GnjLa6giLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt # Import matplotlib\n",
        "\n",
        "# Load a video (replace with your video path or a small sample video if possible)\n",
        "video_path = \"your_video.mp4\"  # Replace with your video file path (or upload one to Colab)\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error opening video\")\n",
        "else:\n",
        "    ret, frame = cap.read()  # Read a single frame\n",
        "    if ret:\n",
        "        # Resize the frame (for faster processing - Student Code: Resize to (80, 60))\n",
        "        # YOUR CODE HERE\n",
        "        resized_frame = cv2.resize(frame, (80, 60))\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)  # OpenCV uses BGR\n",
        "\n",
        "        # Display the frame (optional)\n",
        "        plt.imshow(gray_frame, cmap='gray')\n",
        "        plt.title(\"Video Frame (Grayscale)\")\n",
        "        plt.show()\n",
        "\n",
        "    cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "XBFGZh4sgiLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Optional: Audio Data (Simplified)\n",
        "\n"
      ],
      "metadata": {
        "id": "-Er6F2PWgiLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an audio file (replace with your audio path)\n",
        "audio_path = \"your_audio.wav\"  # Replace with your audio file path (or upload one to Colab)\n",
        "y, sr = librosa.load(audio_path, duration=5)  # Load a maximum of 5 seconds\n",
        "\n",
        "# Feature extraction (MFCCs - Student Code: Extract 20 MFCCs)\n",
        "# Hint: Use librosa.feature.mfcc() with n_mfcc=20\n",
        "# YOUR CODE HERE\n",
        "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "\n",
        "# Display MFCCs (optional)\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('MFCCs')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Normalize MFCCs (example)\n",
        "mfccs_normalized = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
        "\n",
        "print(\"MFCCs shape:\", mfccs.shape)\n",
        "print(\"Normalized MFCCs shape:\", mfccs_normalized.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "TE_Csd2agiLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tip:** Explore different methods for handling missing values (e.g., backward fill, interpolation).  Consider feature engineering techniques like creating lagged variables.\n",
        "\n",
        "## Questions (Markdown Cell)\n",
        "\n",
        "1.  Why is data preprocessing still important even with deep learning's feature extraction capabilities?\n",
        "2.  Explain the difference between normalization and standardization. When would you choose one over the other?\n",
        "3.  Describe a scenario where data augmentation would be particularly useful.\n",
        "4.  What are some potential challenges or pitfalls to avoid during data preprocessing?  How can you mitigate them?\n",
        "5.  Choose one of the data types covered in the lab (images, text, time series).  Describe a specific real-world application that uses deep learning and explain how preprocessing would be crucial for that application.\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "*   **Completed Notebook (PDF):** This notebook with your code, outputs, and answers to the questions.\n",
        "*   **Reflective Journal:** A short journal (1-2 pages) reflecting on your learning experience in this lab.  Consider the following prompts:\n",
        "    *   What did you learn in this lab?\n",
        "    *   What challenges did you encounter? How did you overcome them?\n",
        "    *   Were there any concepts that you already knew?\n",
        "    *   Did anything surprise you?\n",
        "    *   What are some potential real-world applications of the preprocessing techniques you learned?\n",
        "    *   What further learning or exploration would you like to pursue related to data preprocessing?\n",
        "\n",
        "Remember to save your notebook with the outputs and convert it to PDF before submission. Good luck!\n",
        "```"
      ],
      "metadata": {
        "id": "B0Iid64jgiLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://towardsdatascience.com/text-normalization-with-spacy-and-nltk-1302ff430119\">https://towardsdatascience.com/text-normalization-with-spacy-and-nltk-1302ff430119</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "ATDn3sYsgiLF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}